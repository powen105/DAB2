# -*- coding: utf-8 -*-
"""FINAL_DAB_NB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XkWNGgyx9HNNcUJIO35O085z6jhrj1qZ
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import scipy
import re
import string

# %matplotlib inline
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('vader_lexicon')
nltk.download('averaged_perceptron_tagger')
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.probability import FreqDist
from nltk.tag import pos_tag
from sklearn.linear_model import LinearRegression
from nltk import word_tokenize, sent_tokenize
from wordcloud import WordCloud, STOPWORDS
from textblob import TextBlob
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import wordnet
from nltk.tokenize import word_tokenize, sent_tokenize

import matplotlib.pyplot as plt 
from matplotlib import rcParams
import seaborn as sns
from textblob import TextBlob
from plotly import tools
import plotly.graph_objs as go
from plotly.offline import iplot
# %matplotlib inline

#Ignore warnings
import warnings
warnings.filterwarnings('ignore')

from sklearn.linear_model import LogisticRegression
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud

import statsmodels.api as sm

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("drive/My Drive/beers.csv.zip")

df_Stone = df[(df['brewery_id']==147) & df['style'].str.contains('IPA', na=False, case=False)]
df_Market = df[(df['country']=='US') & df['style'].str.contains('American IPA', na=False, case=False)]

print(df_Stone['id'].nunique())
print(df_Market['id'].nunique())

df2 = pd.read_csv('drive/My Drive/reviews.csv.zip')

df2 = df2.rename(columns = {'beer_id': 'id'}, inplace = False)

Stone_reviews = pd.merge(df_Stone, df2, on="id")
Stone_reviews = Stone_reviews.replace(r'^\s*$', np.nan, regex=True)
Stone_reviews = Stone_reviews.dropna(subset=['text'])

Stone_reviews.isnull().sum()

Market_reviews = pd.merge(df_Market, df2, on="id")
Market_reviews = Market_reviews.replace(r'^\s*$', np.nan, regex=True)
Market_reviews = Market_reviews.dropna(subset=['text'])

Market_reviews.isnull().sum()

"""Word Frequency Counting:"""

all_comments = Stone_reviews['text'].values
cmts=''
for c in all_comments:
  c=c.lower()
  cmts+=c+' '
for ch in '!"~$&()*+<_>?:;-/,.@[]{}~''':
  cmts = cmts.replace(ch,"")
words = cmts.split()

counts = {}
stopwords = stopwords.words('english')
for word in words:
  if word not in stopwords:
    counts[word] = counts.get(word,0) + 1
items = list(counts.items())
items.sort(key=lambda x:x[1], reverse=True)

items=pd.DataFrame(items)
items = items.rename(columns = {0:'Word', 1:'Counts'})
items.head()

items.to_csv('wordcount1')

all_comments = Market_reviews['text'].values
cmts=''
for c in all_comments:
  c=c.lower()
  cmts+=c+' '
for ch in '!"~$&()*+<_>?:;-/,.@[]{}~''':
  cmts = cmts.replace(ch,"")
words = cmts.split()

counts = {}
stopwords = stopwords.words('english')
for word in words:
  if word not in stopwords:
    counts[word] = counts.get(word,0) + 1
items = list(counts.items())
items.sort(key=lambda x:x[1], reverse=True)

items=pd.DataFrame(items)
items = items.rename(columns = {0:'Word', 1:'Counts'})
items.head()

items.to_csv('wordcount2')

"""Punctuation Removal:"""

text_prep = Stone_reviews.copy()

string.punctuation
def punctuation_removal(messy_str):
    clean_list = [char for char in messy_str if char not in string.punctuation]
    clean_str = ''.join(clean_list)
    return clean_str
text_prep['text'] = text_prep['text'].apply(punctuation_removal)

"""Removing stopwords including irrelevant list:"""

stop = stopwords.words('english')

stop = stopwords.words('english')
stop_words = []

for item in stop: 
    new_item = punctuation_removal(item)
    stop_words.append(new_item) 
irrelevant_list =['beer', 'ipa','head','pour','taste','flavor', 'white', 'pint','glass', 'bodi', 'color','good', 'little', 'really', 'one', 'much', 'nose', 'bit', 'great', 'still', 'well', 'definitely', 'lot', 'quite', 'big', 'way', 'though', 'nice']
def stopwords_removal(messy_str):
    messy_str = word_tokenize(messy_str)
    return [word.lower() for word in messy_str 
            if word.lower() not in stop_words and word.lower() not in irrelevant_list ]
text_prep['text'] = text_prep['text'].apply(stopwords_removal)
text_prep['text'].head()

text_prep['text'] = text_prep['text'].apply(lambda x: ' '.join(x))

allWords = ' '.join([twts for twts in text_prep['text']])

def show_wordcloud(data, title = None):
    wordcloud = WordCloud(
        background_color = 'white',
        max_words = 200,
        max_font_size = 40, 
        scale = 3,
        random_state = 42
    ).generate(str(data))

    fig = plt.figure(1, figsize = (20, 20))
    plt.axis('off')
    if title: 
        fig.suptitle(title, fontsize = 20)
        fig.subplots_adjust(top = 2.3)

    plt.imshow(wordcloud)
    plt.show()
    
# print wordcloud
show_wordcloud(allWords)

def preprocess_reviews(Stone_reviews, text):
    stop_words = set(stopwords.words('english'))
    Stone_reviews['text'] = Stone_reviews['text'].str.replace(r'[^\w\s]','', regex=True)
    Stone_reviews['tokens'] = Stone_reviews['text'].apply(lambda x: x.split())
    Stone_reviews['tokens'] = Stone_reviews['tokens'].apply(lambda x: [word for word in x if word.lower() not in stop_words])
    Stone_reviews['tokens'] = Stone_reviews['tokens'].apply(lambda x: ' '.join(x))
    Stone_reviews['Polarity'] = Stone_reviews['tokens'].apply(lambda x: TextBlob(x).sentiment.polarity)
    return Stone_reviews.head(5)

preprocess_reviews(Stone_reviews, "text")

def preprocess_reviews(Market_reviews, text):
    stop_words = set(stopwords.words('english'))
    Market_reviews['text'] = Market_reviews['text'].str.replace(r'[^\w\s]','', regex=True)
    Market_reviews['tokens'] = Market_reviews['text'].apply(lambda x: x.split())
    Market_reviews['tokens'] = Market_reviews['tokens'].apply(lambda x: [word for word in x if word.lower() not in stop_words])
    Market_reviews['tokens'] = Market_reviews['tokens'].apply(lambda x: ' '.join(x))
    Market_reviews['Polarity'] = Market_reviews['tokens'].apply(lambda x: TextBlob(x).sentiment.polarity)
    return Market_reviews.head(5)

preprocess_reviews(Market_reviews, "text")

fig, ax = plt.subplots()

sns.kdeplot(Stone_reviews["Polarity"], shade=True, color="blue", label="Stone Brewing", ax=ax)
sns.kdeplot(Market_reviews["Polarity"], shade=True, color="green", label="American IPA Market", ax=ax)

mean_stone = Stone_reviews["Polarity"].mean()
mean_market = Market_reviews["Polarity"].mean()
ax.axvline(mean_stone, color='blue', linestyle='--', label="Stone's Average Polarity")
ax.axvline(mean_market, color='green', linestyle='--', label="Market's Average Polarity")

ax.set_xlabel("Sentiment Polarity")
ax.set_ylabel("Density")
ax.legend()

fig.suptitle("Figure 2: Distribution of Sentiment Polarity of reviews");

fig, ax = plt.subplots()

sns.kdeplot(Stone_reviews["score"], shade=True, color="blue", label="Stone Brewing", ax=ax)
sns.kdeplot(Market_reviews["score"], shade=True, color="green", label="American IPA Market", ax=ax)

mean_stone = Stone_reviews["score"].mean()
mean_market = Market_reviews["score"].mean()
ax.axvline(mean_stone, color='blue', linestyle='--', label="Stone's Average Rating")
ax.axvline(mean_market, color='green', linestyle='--', label="Market's Average Rating")

ax.set_xlabel("Rating Scores")
ax.set_ylabel("Density")
ax.legend()

fig.suptitle("Figure 3: Distribution of Rating Scores of reviews");

print(Stone_reviews['Polarity'].mean())
print(Market_reviews['Polarity'].mean())

print(Stone_reviews['score'].mean())
print(Market_reviews['score'].mean())

print(Stone_reviews['score'].describe(percentiles=[.9, .1]))

pos_df = text_prep[text_prep.score > 4.65]
neg_df = text_prep[text_prep.score < 3.6]

#Filtering data
pos_df
neg_df

## custom function for ngram generation ##
def generate_ngrams(text, n_gram=1):
    token = [token for token in text.lower().split(" ") if token != "" if token not in STOPWORDS]
    ngrams = zip(*[token[i:] for i in range(n_gram)])
    return [" ".join(ngram) for ngram in ngrams]

## custom function for horizontal bar chart ##
def horizontal_bar_chart(df, color):
    trace = go.Bar(
        y=df["word"].values[::-1],
        x=df["wordcount"].values[::-1],
        showlegend=False,
        orientation = 'h',
        marker=dict(
            color=color,
        ),
    )
    return trace
## Get the bar chart from positive reviews ##
freq_dict = defaultdict(int)
for sent in pos_df["text"]:
    for word in generate_ngrams(sent,2):
        freq_dict[word] += 1
fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])
fd_sorted.columns = ["word", "wordcount"]
trace0 = horizontal_bar_chart(fd_sorted.head(25), 'green')

## Get the bar chart from negative reviews ##
freq_dict = defaultdict(int)
for sent in neg_df["text"]:
    for word in generate_ngrams(sent,2):
        freq_dict[word] += 1
fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])
fd_sorted.columns = ["word", "wordcount"]
trace2 = horizontal_bar_chart(fd_sorted.head(25), 'brown')

# Creating two subplots
fig = tools.make_subplots(rows=2, cols=1, vertical_spacing=0.04,horizontal_spacing=0.25,
                          subplot_titles=["Bigram plots of Positive reviews",
                                          "Bigram plots of Negative reviews"
                                          ])
fig.append_trace(trace0, 1, 1)
fig.append_trace(trace2, 2, 1)


fig['layout'].update(height=1000, width=1000, paper_bgcolor='rgb(233,233,233)', title="Bigram Plots")
iplot(fig, filename='word-plots')

#select the column that you want to add binary indicators to
column = Stone_reviews["text"]

# List of words that you want to create binary indicators for
words = ["hops", "citrus", "malt", "pine", "orange", "grapefruit", "bitter", "sweet", "caramel", "floral","dry","smooth","lemon","thick","pineapple", "balanced", "hazy", "fresh", "tropical", "crisp", "creamy", "fruity", "tea"]

# Create the binary indicators
for word in words:
    Stone_reviews[word] = column.apply(lambda x: 1 if word in x.lower() else 0)

dff = Stone_reviews[ ["Polarity", "score","citrus", "hops", "malt", "pine", "orange", "grapefruit", "bitter", "sweet", "caramel", "floral","dry","lemon","thick", "smooth","pineapple", "balanced", "hazy", "fresh","tropical", "crisp", "creamy", "fruity", "tea"]]

def average_polarity(dff, column1, column2):
  # Extract the rows where column2 is equal to 1
  df_filtered = dff[dff[column2] == 1]
  # Calculate the mean of column1 for these rows
  mean_polarity = df_filtered[column1].mean()
  # Return the mean score
  return mean_polarity

mean_polarity = average_polarity(dff, 'Polarity', 'hops')
print(f'mean polarity = {mean_polarity:.3f}')

def average_score(dff, column1, column2):
  # Extract the rows where column2 is equal to 1
  df_filtered = dff[dff[column2] == 1]
  # Calculate the mean of column1 for these rows
  mean_polarity = df_filtered[column1].mean()
  # Return the mean score
  return mean_polarity

mean_score = average_score(dff, 'score', 'hops')
print(f'mean score =  {mean_score:.3f}')

data=[['hops','flavour', 0.210, 4.154,],['citrus','flavour', 0.210, 4.156],['malt','flavour', 0.202,4.143],['pine','flavour',0.205,4.172],['bitter','trait',0.195,4.121],['grapefruit','flavour',0.203,4.179],['orange','flavour',0.202,4.136],['sweet','trait',0.206,4.144],['floral','flavour',0.212,4.158],['dry','trait',0.184,4.108],['smooth','trait',0.230,4.213],['tropical','flavour',0.204,4.168],['lemon','flavour',0.196,4.059],['caramel','flavour',0.188,4.135],['balanced','trait',0.231,4.229],['fresh','trait',0.227,4.211],['thick','trait',0.183,4.170],['hazy','trait',0.197,4.113],['fruity','flavour',0.210,4.137],['pineapple','flavour',0.205,4.198],['creamy','trait',0.210,4.177],['crisp','trait',0.221,4.179]]
eg=pd.DataFrame(data,columns=['Attribute','type', 'Mean_Polarity', 'Mean_Score'])
eg

plt.scatter(eg['Mean_Polarity'][eg.type=='flavour'], eg['Mean_Score'][eg.type=='flavour'], color='blue', marker='o',s=100)
plt.scatter(eg['Mean_Polarity'][eg.type=='trait'], eg['Mean_Score'][eg.type=='trait'], color='black', marker='x',s=150)
plt.title("Figure 4: Stone Brewing's Average Score and Average Polarity for each Attribute", fontsize=14)
plt.xlabel('Mean Polarity', fontsize=13)
plt.ylabel('Mean Score', fontsize=13)
plt.grid(True, linestyle='--', alpha=0.5)
plt.xlim(0.181, 0.238)
plt.gcf().set_size_inches(10, 7)
plt.text(eg.Mean_Polarity[eg.Attribute=='balanced']+0.001,eg.Mean_Score[eg.Attribute=='balanced']-0.0015,"balanced", fontdict=dict(color='black',size=11),bbox=dict(facecolor='green',alpha=0.5,))
plt.text(eg.Mean_Polarity[eg.Attribute=='smooth']+0.001,eg.Mean_Score[eg.Attribute=='smooth']-0.0015,"smooth", fontdict=dict(color='black',size=11),bbox=dict(facecolor='green',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='fresh']-0.004,eg.Mean_Score[eg.Attribute=='fresh']-0.002,"fresh", fontdict=dict(color='black',size=11),bbox=dict(facecolor='green',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='crisp']+0.001,eg.Mean_Score[eg.Attribute=='crisp']-0.0015,"crisp", fontdict=dict(color='black',size=11),bbox=dict(facecolor='green',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='caramel']-0.0058,eg.Mean_Score[eg.Attribute=='caramel']-0.0018,"caramel", fontdict=dict(color='black',size=11),bbox=dict(facecolor='red',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='lemon']-0.0045,eg.Mean_Score[eg.Attribute=='lemon']-0.002,"lemon", fontdict=dict(color='black',size=11),bbox=dict(facecolor='red',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='dry']+0.001,eg.Mean_Score[eg.Attribute=='dry']-0.0015,"dry", fontdict=dict(color='black',size=11),bbox=dict(facecolor='red',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='thick']+0.001,eg.Mean_Score[eg.Attribute=='thick']-0.0015,"thick", fontdict=dict(color='black',size=11),bbox=dict(facecolor='red',alpha=0.5))
plt.show()

#define the predictor variables and the response variable
X = dff[["citrus", "hops", "pine", "grapefruit", "bitter", "caramel", "floral","dry","lemon","thick", "smooth","pineapple", "balanced", "hazy", "fresh","tropical", "crisp", "creamy"]]

# Add a constant term to the predictor variables
X = sm.add_constant(X)

# Fit the multiple linear regression model
model = sm.OLS(dff['score'], X).fit()

# Print the summary of the model
print(model.summary())

# Check for multicollinearity using VIF
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif_df = pd.DataFrame(vif, index=X.columns, columns=['VIF'])
print(vif_df)

import matplotlib.pyplot as plt
import numpy as np
from matplotlib.colors import LinearSegmentedColormap

# data and standard errors
data = [0.0982, 0.0838, 0.0838, 0.0605, 0.0560, 0.0367, 0.0346, 0.0354, 0.0343, 0.0270, 0.0260, 0.0249, 0.0183, 0.0, 0.0, 0.0, 0.0, -0.0303, -0.0393,-0.0454,-0.0483,  -0.1071]
stderrors = [0.009, 0.008, 0.008, 0.004, 0.007, 0.007, 0.007, 0.01, 0.012, 0.01, 0.009, 0.01, 0.008, 0.0, 0.0, 0.0, 0.0, 0.009, 0.009, 0.007, 0.008, 0.009]
# Creating the color map
cmap = LinearSegmentedColormap.from_list('mycmap', ['green', 'red'])
# Creating a list of colors for each bar
colors = [cmap(i/len(data)) for i in range(len(data))]

# create bar graph
plt.ylim(-0.116, 0.112)
plt.bar(np.arange(len(data)), data, yerr=stderrors, align='center', alpha=0.6, ecolor='black', capsize=3, color=colors)
plt.xticks(np.arange(len(data)), ['BALANCED', 'FRESH', 'SMOOTH', 'GRAPEFRUIT', 'PINE', 'CITRUS','HOPS',  'CRISP', 'PINEAPPLE', 'TROPICAL', 'THICK', 'CREAMY', 'FLORAL', 'SWEET', 'FRUITY', 'ORANGE', 'MALT', 'CARAMEL','HAZY','DRY', 'BITTER',  'LEMON'], rotation=60, ha='center')
plt.gcf().set_size_inches(15, 5)
plt.ylabel('Coefficients')
plt.title('Figure 6: Stone Brewing: Rating Score Coefficients for selected Attributes')
plt.show()

#select the column that you want to add binary indicators to
column = Market_reviews["text"]

# List of words that you want to create binary indicators for
words = ["citrus", "hops", "malt", "pine", "orange", "grapefruit", "bitter", "sweet", "caramel", "floral","dry","lemon","thick", "smooth","pineapple", "balanced", "hazy", "fresh","tropical", "crisp", "creamy", "fruity", "copper", "earthy" ]
# Create the binary indicators
for word in words:
    Market_reviews[word] = column.apply(lambda x: 1 if word in x.lower() else 0)

dff1 = Market_reviews[["Polarity", "score", "citrus", "hops", "malt", "pine", "orange", "grapefruit", "bitter", "sweet", "caramel", "floral","dry","lemon","thick", "smooth","pineapple", "balanced", "hazy", "fresh","tropical", "crisp", "creamy", "fruity", "copper", "earthy" ]]

def average_polarity(dff1, column1, column2):
  # Extract the rows where column2 is equal to 1
  df_filtered = dff1[dff1[column2] == 1]
  # Calculate the mean of column1 for these rows
  mean_polarity = df_filtered[column1].mean()
  # Return the mean score
  return mean_polarity

mean_polarity = average_polarity(dff1, 'Polarity', 'caramel')
print(f'mean polarity = {mean_polarity:.3f}')

def average_score(dff1, column1, column2):
  # Extract the rows where column2 is equal to 1
  df_filtered = dff1[dff1[column2] == 1]
  # Calculate the mean of column1 for these rows
  mean_polarity = df_filtered[column1].mean()
  # Return the mean score
  return mean_polarity

mean_score = average_score(dff1, 'score', 'pine')
print(f'mean score =  {mean_score:.3f}')

data= [['hops','flavour', 0.204, 3.949 ],['citrus','flavour', 0.207, 3.980],['malt','flavour', 0.196,3.938],['pine','flavour',0.206,3.989],['bitter','trait',0.194,3.927],['grapefruit','flavour',0.206,4.023],['orange','flavour',0.202,3.964],['sweet','trait',0.205,3.955],['floral','flavour',0.209,3.955],['dry','trait',0.182,3.953],['fruity','flavour',0.206,4.004],['smooth','trait',0.234,4.053],['tropical','flavour',0.208,4.085],['lemon','flavour',0.199,3.970],['caramel','flavour',0.186,3.899],['balanced','trait',0.228,4.036],['fresh','trait',0.225,4.036],['thick','trait',0.178,3.991],['hazy','trait',0.196,3.962],['fruity','flavour',0.210,3.993],['pineapple','flavour',0.209,4.107],['creamy','trait',0.210,4.024],['crisp','trait',0.216,3.995],['copper','flavour',0.197,3.894],['earthy','flavour', 0.184,3.888]]
eg = pd.DataFrame(data,columns=['Attribute','type', 'Mean_Polarity', 'Mean_Score'])
eg

plt.scatter(eg['Mean_Polarity'][eg.type=='flavour'], eg['Mean_Score'][eg.type=='flavour'], color='blue', marker='o',s=100)
plt.scatter(eg['Mean_Polarity'][eg.type=='trait'], eg['Mean_Score'][eg.type=='trait'], color='black', marker='x',s=150)
plt.title("Figure 5: The Market's Average Score and Average Polarity for each Attribute", fontsize=14)
plt.xlabel('Mean Polarity', fontsize=13)
plt.ylabel('Mean Score', fontsize=13)
plt.grid(True, linestyle='--', alpha=0.5)
plt.xlim(0.177, 0.237)
plt.gcf().set_size_inches(10, 7)
plt.text(eg.Mean_Polarity[eg.Attribute=='balanced']+0.001,eg.Mean_Score[eg.Attribute=='balanced']-0.0015,"balanced", fontdict=dict(color='black',size=11),bbox=dict(facecolor='green',alpha=0.5,))
plt.text(eg.Mean_Polarity[eg.Attribute=='pineapple']+0.001,eg.Mean_Score[eg.Attribute=='pineapple']-0.0015,"pineapple", fontdict=dict(color='black',size=11),bbox=dict(facecolor='green',alpha=0.5,))
plt.text(eg.Mean_Polarity[eg.Attribute=='tropical']+0.001,eg.Mean_Score[eg.Attribute=='tropical']-0.0015,"tropical", fontdict=dict(color='black',size=11),bbox=dict(facecolor='green',alpha=0.5,))
plt.text(eg.Mean_Polarity[eg.Attribute=='smooth']-0.0025,eg.Mean_Score[eg.Attribute=='smooth']+0.007,"smooth", fontdict=dict(color='black',size=11),bbox=dict(facecolor='green',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='fresh']-0.0043,eg.Mean_Score[eg.Attribute=='fresh']-0.002,"fresh", fontdict=dict(color='black',size=11),bbox=dict(facecolor='green',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='caramel']-0.0025,eg.Mean_Score[eg.Attribute=='caramel']+0.007,"caramel", fontdict=dict(color='black',size=11),bbox=dict(facecolor='red',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='earthy']-0.0052,eg.Mean_Score[eg.Attribute=='earthy']-0.002,"earthy", fontdict=dict(color='black',size=11),bbox=dict(facecolor='red',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='dry']+0.001,eg.Mean_Score[eg.Attribute=='dry']-0.0015,"dry", fontdict=dict(color='black',size=11),bbox=dict(facecolor='red',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='thick']+0.001,eg.Mean_Score[eg.Attribute=='thick']-0.0015,"thick", fontdict=dict(color='black',size=11),bbox=dict(facecolor='red',alpha=0.5))
plt.text(eg.Mean_Polarity[eg.Attribute=='copper']-0.005,eg.Mean_Score[eg.Attribute=='copper']-0.001,"copper", fontdict=dict(color='black',size=11),bbox=dict(facecolor='red',alpha=0.5))
plt.show()

#define the predictor variables and the response variable
X = dff1[["citrus", "malt", "pine", "grapefruit", "bitter", "sweet", "caramel", "floral","dry","lemon","thick", "smooth","pineapple", "balanced", "fresh","tropical", "crisp", "creamy", "fruity", "copper", "earthy" ]]
# Add a constant term to the predictor variables
X = sm.add_constant(X)

# Fit the multiple linear regression model
model = sm.OLS(dff1['score'], X).fit()

# Print the summary of the model
print(model.summary())

# Check for multicollinearity using VIF
from statsmodels.stats.outliers_influence import variance_inflation_factor
vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif_df = pd.DataFrame(vif, index=X.columns, columns=['VIF'])
print(vif_df)

import matplotlib.pyplot as plt
import numpy as np
from matplotlib.colors import LinearSegmentedColormap

data = [0.1190, 0.1137, 0.1136, 0.0968, 0.0924, 0.0808, 0.0729, 0.0592, 0.0525, 0.0418, 0.0346, 0.0309, 0.0133, 0.0129, 0.0000, 0.0000, 0.0000, -0.0057, -0.0219, -0.0415, -0.0554, -0.0576, -0.0738, -0.0750]
stderrors = [0.003, 0.003, 0.003, 0.002, 0.002, 0.004, 0.002, 0.003, 0.002, 0.003, 0.003, 0.003, 0.002, 0.002, 0.0000, 0.0000, 0.0000, 0.002, 0.003, 0.003, 0.003, 0.002, 0.003, 0.002]

# Creating the color map
cmap = LinearSegmentedColormap.from_list('mycmap', ['green', 'red'])
# Creating a list of colors for each bar
colors = [cmap(i/len(data)) for i in range(len(data))]

# create bar graph
plt.ylim(-0.09, 0.13)
plt.bar(np.arange(len(data)), data, yerr=stderrors, align='center', alpha=0.6, ecolor='black', capsize=3, color=colors)
plt.xticks(np.arange(len(data)), [ 'TROPICAL', 'BALANCED', 'SMOOTH', 'FRESH', 'GRAPEFRUIT', 'PINEAPPLE', 'CITRUS', 'CREAMY', 'PINE', 'THICK', 'FRUITY', 'CRISP', 'SWEET', 'FLORAL', 'HAZY', 'HOPS', 'ORANGE', 'DRY', 'LEMON', 'COPPER', 'EARTHY', 'BITTER', 'CARAMEL', 'MALT'], rotation=60, ha='center')
plt.gcf().set_size_inches(15, 5)
plt.ylabel('Coefficients')
plt.title('Figure 7: Market: Rating Score Coefficients for selected Attributes ')
plt.show()